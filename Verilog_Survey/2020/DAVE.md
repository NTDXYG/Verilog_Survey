# DAVE: Deriving Automatically Verilog from English

## 基本信息
- **会议/期刊**: MLCAD
- **发表时间**: 2020.11
- **作者**: Hammond Pearce, Benjamin Tan, Ramesh Karr
- **作者单位**: New York University
  
## 摘要
数字系统的设计规范通常以自然语言形式呈现，工程师需要投入大量精力将这些规范转换为数字系统编译器可理解的编程语言。通过自动化这一转换过程，设计人员可以专注于使用自然语言进行系统描述，从而将更多精力投入到其他下游设计挑战中。

本文探索了利用最先进的机器学习（ML）技术，通过微调 GPT-2 模型，实现从英语到 Verilog 代码片段的自动转换。研究构建了一个专门面向新手级数字设计任务的数据集，并在此基础上对 GPT-2 模型进行了深入探索。实验结果表明，该系统在提出的数据集上展现出优异的转换性能（正确率达到 94.8%），能够同时处理简单和抽象的设计任务。

## 研究背景
在数字系统设计领域，设计规格通常以自然语言形式呈现，工程师需要耗费大量精力将这些自然语言规格转换为硬件描述语言（如 Verilog）。这一手动翻译过程不仅要求工程师具备深厚的领域知识，还难以保证代码的完全正确性。与此同时，机器学习（ML）在集成电路（IC）计算机辅助设计（CAD）流程中已取得显著成果，例如在硬件成本估算、逻辑综合和物理设计等方面。此外，随着深度学习（DL）的发展，自然语言处理（NLP）领域也取得了突破性进展，以 GPT-2 为代表的模型在语言生成和翻译任务中展现出卓越性能。

## 研究动机
鉴于手动将自然语言规格转换为 Verilog 的过程效率低下且容易出错，业界一直致力于实现"无人干预"的机器驱动设计流程（即端到端生成）。机器学习在自然语言处理和 CAD 领域的成功应用为解决这一问题提供了新思路。特别是 GPT-2 模型展现出的强大自然语言处理能力，促使研究者思考：能否利用这种能力，将任务描述直接转换为硬件实现，从而提高设计效率并减轻设计师的工作负担。

## 主要贡献
- **DAVE 模型**：开发了一个基于 GPT-2 的预训练模型，能够将自然语言描述转换为 Verilog 实现。
- **创新数据集**：提出了一种自动生成大规模英文规格与 Verilog 对应关系的方法，用于 DAVE 模型的微调。
- **模型评估体系**：对 DAVE 的微调过程进行了深入探索和系统评估，验证了其在不同任务集上的翻译性能。
- **复杂任务处理**：评估了 DAVE 在翻译复杂描述性任务方面的能力，突破了简单规定性形式的局限。

## 数据集
![DAVE数据集示例](figs/dave_dataset.png "Figure 1 from DAVE paper: Example of English to Verilog translation")

### 模板驱动的数据集构造方法
![DAVE数据集构造方法](figs/dave_dataset_method.png "Figure 2 from DAVE paper: Example of English to Verilog translation")

1. **生成任务/结果元结构**
   定义任务类型（如组合逻辑赋值、寄存器、序列生成器等）和关键信息（变量名、运算符、输入输出关系等）。元结构示例：
   ```verilog
   Type: SimpleAssignment
   I1: a, I2: b, 
   O: c, 
   Operator: OR
   ```

2. **选择合适模板**
   从模板库中随机选取匹配元结构的自然语言模板和 Verilog 模板。自然语言模板描述任务需求（如"定义组合逻辑代码，在'c'中返回'a' OR 'b'的结果"），Verilog 模板定义对应的代码结构（如"assign {{.O}} = {{.I1}} {{.Op}} {{.I2}};"）。

3. **填充模板内容**
   将元结构中的参数（如变量名、运算符）替换到模板中，生成具体的任务对。例如：

   TASK: Define combinational code to return 'a' OR 'b' in 'c'. 

   RESULT:
   ```verilog
   assign c = a | b;
   ```

4. **存储任务对**
   将生成的"任务-结果"对按类别保存，用于模型训练和评估。

### 数据集类型分类
- **规定性模板（Prescriptive templates）**：结构直接，如"将'a'和'b'的或运算结果存入'c'"，翻译时仅需词语替换和语序调整。
- **描述性模板（Descriptive templates）**：更复杂，需要隐含逻辑理解，如图1中的自然语言描述，需要推断时钟、寄存器等硬件元素。
- **多任务（Multi Task）**：随机串联2-4个单一任务，如同时定义寄存器和组合逻辑，考验模型处理复杂场景的能力。

### 数据集多样性
- **可选子句机制**：模板中包含可选子句（如复位信号描述），生成数据时可根据元结构需求添加或省略，增加任务实例的差异性。
- **场景随机化**：描述性模板引入随机场景（如"飞机呼叫按钮"、"房屋报警传感器"），通过级联子模板生成多样化描述，提升数据熵。

### 数据集泛化性
保留部分模板（非训练模板）在微调阶段不参与训练，用于测试模型对未见过的任务结构和描述方式的泛化能力。

## 方法
- **模型选择**：以 GPT-2 为基础模型，进行监督微调
- **超参数设置**：学习率 1e-4

## 实验设计
- **评估指标**：采用 Ratcliff-Obershelp 相似度度量生成的 Verilog 与模板提供的"正确"答案的接近程度，排除空白字符影响。
- **测试集划分**：
  1. 训练模板：用于模型微调，占生成样本的 95%
  2. 非训练模板：未在微调阶段出现，用于评估模型的泛化能力
- **任务类型测试**：分别对规定性任务、描述性任务和多任务进行测试，观察模型在不同难度任务上的表现。
- **数据规模**：
  1. 单一任务：生成数千个任务对，覆盖赋值（pa系列）、寄存器（pr系列）、序列生成器（pg系列）等类型
  2. 多任务：随机生成5250个样本，其中5000个用于微调，250个用于验证

![DAVE数据集规模分析](figs/dave_dataset_table.png "Figure 3 from DAVE paper: Dataset size analysis")

## 实验结果
- **整体性能**：DAVE在所有验证测试中返回正确答案的比例为94.8%，展现出优异的翻译准确率。
- **分任务表现**：
  1. 规定性任务：训练模板上准确率高达99.7%，非训练模板上为96.5%，但序列生成器任务在非训练模板上表现稍差（85.6%）
  2. 描述性任务：表现优于规定性任务，训练模板上赋值任务和寄存器任务的准确率分别为99.2%和99.0%，非训练模板上赋值任务达100%，寄存器任务为98%
  3. 多任务：性能相对较低，训练模板上正确率为52%，非训练模板上为41.2%，主要错误集中在变量名和运算符选择上

## 创新点
- 首次将 GPT-2 等先进的自然语言处理模型应用于从自然语言生成硬件描述语言（HDL）的任务
- 提出了一种基于模板的大规模数据集自动生成方法
- 建立了详尽的实验评估体系与结果分析框架

## 局限性
- **数据集限制**：数据集采用模板生成，虽然覆盖了多种任务类型，但可能限制了模型对更自由形式自然语言描述的处理能力，且训练数据中每个任务模板与 Verilog 实现是多对一关系，未充分考虑功能等价的不同实现方式
- **基座模型限制**：受 GPT-2 模型本身限制，输出长度最多为1024个tokens，导致无法处理过长的代码片段，如序列生成器任务被限制为最多4个元素，多任务也不能使用过长的描述性寄存器模板
- **创造性不足**：模型生成的结果依赖于训练数据中的模式，缺乏创造性，无法生成训练数据中未出现的新的信号或实现方式

## 未来工作
- **模型优化**：探索使用更大规模的 GPT-2 模型，以提高模型的表达能力和处理更复杂任务的能力
- **任务拓展**：增加任务的复杂度和长度，如处理更复杂的状态机、更长的序列生成器以及具有更多相关子任务的多任务场景
- **特定任务优化**：针对特定应用场景，如从自然语言生成安全断言，对 DAVE 进行专门优化和调整
- **数据集改进**：丰富数据集的多样性，引入更多自由形式的自然语言描述，考虑功能等价的不同 Verilog 实现，提高模型的泛化能力和创造性

## 笔记
[待补充]