# Large Language Models for Code: Security Hardening and Adversarial Testing
## 基本信息

- **​会议/期刊**​​: ACM SIGSAC Conference on Computer and Communications Security (CCS'23)
- **​发表时间**​​: 2023.11
- **作者​**​: Jingxuan He, Martin Vechev
- **作者单位**​​: ETH Zurich, Switzerland

## 摘要
大型语言模型（LLM）在代码生成领域应用广泛，但常产生不安全代码。本文提出安全强化和对抗测试的双重安全框架，通过受控代码生成任务实现：输入二元安全属性（安全/不安全）指导LLM生成对应代码，同时保持功能正确性。我们开发了SVEN方法，利用连续前缀向量在不修改模型权重的前提下实现安全控制。实验表明SVEN显著提升安全率（CodeGen-2.7B从59.1%→92.3%），对抗测试时安全率降至36.8%，且功能正确性与原始模型相当。

## 研究背景
LLM代码生成器（如GitHub Copilot）已在开发中广泛应用，但研究发现40%的生成代码存在高危漏洞（如MITRE TOP-25弱点）。现有安全改进方案存在局限：

- 规则过滤（如Copilot）仅覆盖少数漏洞类型
- 微调整个模型计算成本高昂
- 漏洞数据集质量差，含无关代码变更
## 研究动机
解决三大核心挑战：
- ​模块化​​：避免修改LLM权重，适应大模型部署
- ​安全-功能平衡​​：安全控制不影响代码功能正确性
- ​数据质量​​：构建高质量安全修复数据集 
## 主要贡献
1、​新安全任务​​：受控代码生成（Controlled Code Generation），支持安全强化和对抗测试

2、​​SVEN框架​​：
  
![alt text](figs/LLM_for_Code/SVEN.png)

- 推理：属性特定连续前缀引导生成

- 训练：代码区域差异化损失函数
​​高质量数据集​​：手动筛选1,606个安全修复样本（覆盖9种CWE）

3、​全面评估​​：在13种漏洞、3种LLM上验证有效性
## 方法
**​核心架构**：
- 安全属性设置：为每一个样本设计一个安全属性c，表示该样本是安全样本或不安全样本
- ​​连续前缀​​：为每个安全属性c（sec/vul）训练专属前缀向量
​- ​轻量化​​：仅增加0.1%参数（例：CodeGen-2.7B仅需8个前缀token）
- 标记向量m：用于表示训练程序中哪些元素被修改（掩码）
- 掩码维度：字符，行，程序​
- 文中方法采用​混合掩码训练​​：对安全程序采用字符级掩码，对不安全程序采用行级掩码

**​损失函数**:

​![alt text](figs/LLM_for_Code/overall-loss.png)
三个损失函数分别代表
- 安全敏感区域的条件建模
- 安全/不安全代码对比损失
- 未修改区域的KL散度正则化

​**​数据集构建**：

1、​筛选标准​​：
- 仅包含真实安全修复（非重构/功能更新）
- 需要能够适用于日常代码补全场景，并且不应过度依赖于特定项目或漏洞。

2、构建步骤：
- 筛选符合条件的数据集，最终选择了CrossVul [58]和Big-Vul [34]（基于C/C++）和VUDENC [76]（基于python）
- 在数据集中寻找真正的安全修复，我们对[34,58,76]中针对目标CWE的提交进行了人工检查，提取真正的安全修复代码对，并排除质量问题。（人工检查是必要的，因为这些问题无法通过自动化手段准确检测。重要的是，我们的手动审查基于领域专业知识，而不是在测试集上调整训练集。）
- 最终训练和验证数据集，涵盖了9个CWE。我们选择这些CWE是因为：(i)它们均被列入MITRE的前25名，因此至关重要；（ii）我们能够为这些CWE提取超过40个安全修复案例；（iii）可以进行自动化的安全评估[60,68]
![alt text](figs/LLM_for_Code/dataset.png)
- 训练粒度：一次性处理所有CWE。我们进行一次训练，生成两个前缀SVENsec和SVENvul，这两个前缀能够同时解决训练数据集中捕获的所有CWE。这一设计决策与实际的安全加固和对抗测试目标一致：我们的目标是保护语言模型（LM）免受广泛的安全问题，而对手则可能试图引入尽可能多的漏洞。此外，这种方法相比为每个特定的CWE进行多次训练，具有更高的简洁性。
## 实验设计
**1、模型选择**

多语言版本的CodeGen，参数量为：350M、2.7B和6.1B 、InCoder 和SantaCoder

**2、安全评估**

- ​基准​​：MITRE TOP-25漏洞场景
- ​方法​​：对每个场景（一个特定的CWE+提示）生成25个代码样本，过滤掉重复或无法编译或解析的程序，得到一组有效程序，然后用CodeQL分析检测漏洞，最后计算安全率（安全/有效）。其中每次实验重复10次，使用不同的种子，并报告平均安全率以及95%的置信区间
- ​提示改造​​：将Copilot的填充式提示转为左向右生成格式

**3、功能正确性评估**

采用HumanEval基准，计算pass@k指标时，针对每个k值，在4个常见的采样温度下运行模型取最佳值
## 实验结果
**1、安全性评估**

不同温度下的总体安全性：

![alt text](figs/LLM_for_Code/overall-cecurityu.png)
温度对结果的影响：较低温度下SVEN的安全控制能力更强，而普通LLM的能力对温度相对不敏感

在各CWE上的表现：
![alt text](figs/LLM_for_Code/cwe-security.png)
SVENsec方案在绝大多数情况下都能提升或保持安全率
SVENvul方案在五个CWE场景（CWE-089、CWE-078、CWE-476、CWE-022和CWE-079）中安全率较低，并对CWE-125场景的安全率造成轻微下降。其他场景下，SVENvul表现与LM基本持平

**2、功能正确性评估**
![alt text](figs/LLM_for_Code/functionally-correct.png)
在不同模型尺寸下，SVENsec和SVENvu的pass@𝑘分数与LLM高度吻合，仅在某些情况下出现轻微性能下降。

**3、消融实验设计**
- 损失函数中的权重设置
![alt text](figs/LLM_for_Code/weight-of-loss.png)
- 连续前缀方案和文本提示方法的对比
  ![alt text](figs/LLM_for_Code/SVEN-and-text.png)
  构建了一个名为“text”的基线模型，该模型使用了“以下代码是安全的”和“以下代码是易受攻击的”作为文本提示来控制语言模型。图13显示，这种基线模型未能实现任何安全控制。此外，我们在训练集上使用这些文本提示对整个语言模型进行了微调，从而得到了一个名为“text-ft”的模型。“text-ft”无法保障安全性，反而彻底破坏了功能的正确性。这项实验充分证明了我们提出的连续前缀方案在性能上的优越性，远超所考虑的文本提示方法。
- 掩码策略的重要性
  “程序”等同于不区分代码区域。图13显示，它在这三个基线和SVEN中表现最差，这表明我们在训练过程中对安全敏感代码区域和中立代码区域的区分对于安全控制至关重要。
- 数据集优化的好处
  为了验证手动整理的效果，我们构建了一个基线数据集，该数据集包含了[34,58,76]提交中所有更改的程序对。这个基线数据集是我们整理数据集的扩展，规模是我们的整理数据集的∼19倍，包含15,207个程序对。使用基线数据集训练了一个名为“无整理”的模型，该模型与SVEN的训练超参数相同。需要注意的是，“无整理”模型由于需要处理∼19倍更多的训练数据，因此训练时间也增加了∼19倍。从图13的对比中可以看出，SVEN在安全控制和功能正确性方面均优于“无整理”模型。这不仅证实了手动数据整理的必要性，还表明在我们的任务中，数据质量应优先于数量.
**可泛化性研究**
- 扰动
  ![alt text](figs/LLM_for_Code/perturbation.png)
  (i) con，即从“CWE-089 0-py”派生的基本场景；（ii）m-∗，涉及元类型变化的场景；（iii）d-∗，涉及文档（注释）变化的场景；（iv）c-∗，涉及代码变化的场景。附录A中详细描述了这些扰动。研究发现，Copilot在这些扰动下的安全性波动较大。我们再次使用这一实验来评估SVEN在不同扰动条件下的稳健性，并在图14中展示了结果。尽管CodeGen LM的安全率也像Copilot一样波动，但SVEN表现出了一致的安全控制：SVENsec达到了100%的安全率，而SVENvul的安全率则保持在1.6%以下。
- 不同LLM
  ![alt text](figs/LLM_for_Code/otherLLM.png)
  了评估安全性，我们使用了主要的CWE，但不得不排除三个C/C++的CWE（即CWE-476、CWE-416和CWE-190），以确保结果的有效性。这是因为SantaCoder对C/C++的训练不足，经常导致编译错误。
- 未见过的测试集
  ![alt text](figs/LLM_for_Code/otherdataset.png)


## 局限性
1. ​​安全行为覆盖不足​​
​​问题​​：SVEN对部分安全漏洞（如第6.4节未训练CWEs）泛化能力有限，且仅支持Python/C++。
​​改进方案​​：
​​拓展数据集​​：构建涵盖更多安全行为的训练集（如MITRE TOP-25未覆盖漏洞）。
​​自动化修复识别​​：集成CodeQL等工具自动提取安全修复模式。
​​众包生态​​：建立用户提交漏洞样本的反馈机制（如Copilot用户报告不安全生成结果）。
2. ​​功能正确性优化瓶颈​​
​​问题​​：KL损失仅通过约束token概率差异​​间接​​保持功能正确性。
​​改进方案​​：
​​强化学习​​：引入基于单元测试执行的奖励机制（如pass@k分数），直接优化功能正确性[48]。
二、架构演进方向
1. ​​提示依赖增强​​
​​当前限制​​：SVEN前缀与用户提示完全独立，限制上下文感知能力。
​​改进方案​​：建立​​前缀-提示动态耦合机制​​，例如：
基于提示语义生成自适应前缀（如安全关键提示触发强化模式）。
引入注意力门控，融合提示关键词与安全属性向量。
## Q&A
1. 为什么60中的提示方法需要做修改：
   ![alt text](figs/LLM_for_Code/QA1.png)
   问题：CodeGen等主流LLM仅支持​​自左向右生成​​（Left-to-right Generation）

   解决方案​​：将填充式提示转换为左向右格式（图6a），确保所有模型在相同模式下评估
2. 对抗测试的意义是什么
   
   对抗测试（Adversarial Testing）的核心意义在于​​从攻击者的视角评估模型的安全性​​，通过主动尝试诱导模型生成不安全代码，暴露其潜在漏洞，从而帮助改进模型的防御能力。具体来说，对抗测试的意义体现在以下几个方面：
3. 为什么选用这样的训练粒度：一次性处理所有CWE
   本文采用​​一次性训练解决所有CWE​​的设计策略（而非按CWE类型分次训练），主要基于以下三个关键考量：

   ​安全场景的实际需求匹配​​：
   ​防御视角（安全加固）​​：在实际开发环境中，开发者需要模型能同时防御多种漏洞类型（如SQL注入、路径遍历、缓冲区溢出等）。
   ​攻击视角（对抗测试）​​：攻击者会尝试注入任意类型的漏洞，而非局限于单一CWE。
   ​​设计一致性​​：单一前缀（SVENsec/SVENvul）统一处理所有CWE，符合真实场景中"全面防护"或"全面攻击"的需求。

   ​训练效率与资源优化​​：
   ​计算成本​​：大型语言模型（如CodeGen-6.1B）单次训练需消耗80GB GPU内存和数小时时间。分CWE训练会使总成本呈倍数增长（9种CWE需9倍资源）。
   ​参数复用​​：连续前缀（仅占模型0.1%参数）可共享底层模型的知识表示。
   
   安全行为的协同学习​​：
   ​​跨漏洞泛化​​：安全修复存在共性模式（如输入验证、内存管理）。例如：
   CWE-089（SQL注入）与CWE-078（命令注入）均需对用户输入消毒
   CWE-125（越界读）与CWE-787（越界写）均需边界检查
   ​​联合训练优势​​：如表1所示，数据集中不同CWE样本量差异显著（CWE-089: 408样本，CWE-190: 86样本）。联合训练使低频CWE从高频CWE中迁移学习安全模式。