# VerilogEval: Evaluating Large Language Models for Verilog Code Generation
Add commentMore actions
## 基本信息
- **会议/期刊**: International Conference on Computer Aided Design (ICCAD 2023) CCF-B
- **发表时间**: 2023.11
- **作者**: Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, and Haoxing Ren
- **作者单位**: Nvidia
  https://github.com/NVlabs/verilog-eval/tree/release/1.0.0

## 摘要
LLM的日益普及为它们在不同领域的应用铺平了道路。本文提出了一个基准测试框架VerilogEval，专门用于在用于硬件设计和验证的Verilog代码生成任务中评估 LLM 性能。VerilogEval包含来自Verilog教学网站HDLBits的156个问题，范围从简单的组合电路到复杂的有限状态机。
通过将生成的设计的仿真输出与预定义的解决方案进行比较，可以自动测试Verilog代码完成的功能正确性。我们还证明，通过使用LLM生成的合成问题代码对进行引导，可以通过监督微调来提高预训练语言模型的 Verilog 代码生成能力。

## 研究背景
近年来，LLMs因其在理解和生成人类语言文本方面的卓越能力而受到广泛关注。这些模型在多个领域展现出了强大的潜力，如金融工程、生物医学研究、科学计算等，并且在编程辅助方面也能够为开发者提供代码片段建议、解决编程难题以及解释复杂概念等帮助。

在电子设计自动化（EDA）领域，LLMs被认为有可能协助工程师进行数字系统的设计和验证，例如提供关于Verilog编码的见解、优化电路以及自动化一些耗时的任务等。Verilog是一种硬件描述语言，用于设计和验证数字电路，因此LLMs在Verilog代码生成方面的应用具有重要的研究价值。

## 研究动机
尽管已经有一些研究开始探索LLMs在Verilog代码生成方面的潜力，但这些研究在评估的全面性、问题数量和多样性方面存在一定的局限性。例如，一些研究仅在少量的设计上进行了评估，或者缺乏对模型性能的深入分析。此外，现有研究在模型微调和数据集构建方面也存在不足，限制了LLMs在Verilog代码生成任务上的进一步发展。


## 主要贡献
- **填补评估工具的空白**：目前缺乏一个专门用于评估LLMs在Verilog代码生成方面性能的全面基准测试框架。因此，研究者们希望开发一个综合性的评估数据集和框架，以更准确地衡量LLMs在这一特定任务上的表现，从而推动该领域的研究进展。
- **降低数据获取成本**：获取大量标记数据通常成本较高，这限制了模型训练和微调的规模。研究者们希望通过探索自我指导的方法，利用LLMs生成的问题-代码对来创建合成的监督微调数据集，以减少对真实标记数据的依赖，同时提高模型的性能。（LLM数据合成）
- **推动LLMs在硬件设计领域的应用**：通过提高LLMs在Verilog代码生成方面的性能和可靠性，研究者们希望能够推动LLMs在硬件设计自动化领域的应用，为未来的硬件设计和验证带来新的可能性和创新方法。

## 数据集
- **VerilogEval-machine**：由gpt-3.5-turbo进行数据合成。通过问题描述生成--验证--迭代采样，最终生成了143个有效的问题描述和解决方案。
（1）问题描述生成：使用LLMs（如gpt-3.5-turbo）根据给定的Verilog代码模块生成自然语言描述。这些描述包括模块的功能、输入输出定义等。
（2）验证：生成的问题描述会通过LLMs生成代码解决方案进行验证。如果生成的代码能够通过测试，则认为问题描述是有效的。如果在100个样本中没有一个生成的代码能够通过测试，则该描述会被丢弃。
（3）迭代采样：对于未解决的问题，使用生成的有效描述作为few-shot示例，继续采样新的问题描述和代码对，直到达到预设的采样预算。

- **VerilogEval-human**：将HDLBits网站上的问题描述手动转换为适合LLMs处理的文本格式。通过人工转换--处理模糊性--详细说明--状态转换图，手动转换了156个问题描述。
（1）人工转换：人工审查HDLBits网站上的问题描述，将其转换为纯文本格式。这包括将电路图、状态转换图、布尔逻辑表和Karnaugh图等转换为文本描述。
（2）处理模糊性：特别关注解决描述中的模糊性，例如时钟的上升沿或下降沿触发、复位和使能信号的高低电平状态以及同步或异步操作等。
（3）详细说明：对于顺序波形，详细列出每个时钟边沿的信号值，以表格形式呈现，并增加时间步列。
（4）状态转换图：对于状态转换图，采用边列表格式进行描述，以确保LLMs能够理解和处理。

- **800多个训练集**：没开源。
  
## 方法
- **模型选择**：以 CodeGen-350M、2B、6B和16B 为基础模型，进行监督微调
- **超参数设置**：学习率 2e-5

## 实验设计
- **评估指标**：采用pass@k (1, 5, 10)。

## 实验结果
- **训练周期对性能的影响**：研究了SFT训练周期对模型性能（pass@k）的影响，并分析了过拟合现象。
- **模型大小和基础模型对性能的影响**：比较了不同模型大小和基础模型（如codegen-nl、codegen-multi和codegen-verilog）在SFT后的性能。
- **SFT数据质量的影响**：通过引入错误的数据进行训练，评估了SFT数据质量对模型性能的影响。

## 创新点
- 新的benchmark，更多样本，更丰富的多样性/复杂性。

## 局限性
- **数据集粒度**：当前的VerilogEval专注于生成自包含的Verilog模块，未来的工作可以探索如何支持更大规模的系统级设计，包括模块实例化和其他复杂硬件设计概念。

## 未来工作
- **系统级设计的支持**：当前的VerilogEval专注于生成自包含的Verilog模块，未来的工作可以探索如何支持更大规模的系统级设计，包括模块实例化和其他复杂硬件设计概念。

- **设计验证**：研究如何使用LLMs来增强硬件设计验证过程，包括检查设计在不同条件下的功能和可靠性。

- **提高SFT数据的多样性和质量**：研究如何生成更多样化和高质量的SFT数据，以进一步提高模型在特定任务上的性能。

- **探索不同的微调技术**：除了有监督的微调，还可以研究RL/RAG等方法，以提高模型对特定任务的适应性。

- **安全性和鲁棒性**：研究如何确保使用LLMs生成的硬件设计代码的安全性和鲁棒性，特别是在面对潜在的恶意输入时。

## 笔记
[待补充]