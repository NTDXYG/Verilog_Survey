# MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation

## 基本信息
- **会议/期刊**: IEEE
- **发表时间**: 2024.07
- **作者**: Yongan Zhang, Zhongzhi Yu, Yonggan Fu, Cheng Wan, Yingyan (Celine) Lin
- **作者单位**: 佐治亚理工学院 (Georgia Institute of Technology)
  
## 摘要
现有的公开硬件数据集在规模、复杂性和细节粒度上的局限性，严重阻碍了大型语言模型在硬件设计任务中的性能。
本文提出多粒度Verilog（MG-Verilog）数据集，
包含超过11,000个具有三级描述粒度
（高级/详细/模块级）的Verilog代码样本，
并设计平衡微调方案以充分挖掘数据潜力。
实验表明，基于该数据集微调的LLMs在Verilog代码生
成准确率上显著优于基线（最高达69.9%），
且在跨复杂度指令下展现强鲁棒性。
## 研究背景
现有的通用LLM， 例如OpenAI的GPT-4 ，在生成实用的硬件设计
方面仍然能力有限。最近的研究表明，在LLM推理、微调或预训练的范围内，
融入额外的特定领域数据对于提升LLM在硬件设计任务中的性能至关重要。
数据集的规模、复杂性和细节粒度是提高LLM性能的关键因素。
然而，现有数据集往往在一个或多个方面存在不足。
这种不足可能会限制微调后的LLM在面对多样化用户指令时的泛化性能，
从而降低其有效性。
## 研究动机
为了解决现有数据集的局限性， 并释放LLM微调和上下文学习在硬
件设计任务中的全部潜力，
提出了一个多粒度Verilog（MG-Verilog）数据集。
该数据集包含不同详细程度的硬件描述及其对应的具有不同设计复
杂度的Verilog代码样本。这些特性使其适用于LLM的推理和微调阶段，
以增强其在硬件设计任务中的性能。
## 主要贡献
- **高质量硬件数据集标准**：提出4大标准：规模、准确性、多粒度描述、可扩展性，这些标准可以作为该领域未来数据集开发的指南。
- **开源的MG-Verilog数据集**：此数据集满足以上标准，用以促进该领域的协作和进一步研究。
- **平衡微调方案**：该方案验证并展示了该数据集在实现LLM辅助硬件设计方面的潜力。
- **高性能的硬件设计LLM**：基于此MG-Verilog数据集微调的LLM，在代码实现的准确性和生成硬件设计的复杂度方面， 
均优于使用其他来源数据集训练的模型。

## 数据集
https://github.com/luke-avionics/mg-verilog
![MG-Verilog数据集示例](figs/fig-1.png " Illustrating the proposed MG-Verilog dataset structure
and examples of varying levels of detail.
")
图示为数据集结构

## 用于LLM辅助硬件设计的数据集标准
为了创建用于LLM辅助硬件设计的高质量数据集，
首先建立设计标准来指导MG-Verilog数据集的开发。
1. **足够的数据集规模：**
这对于LLM的训练和推理都至关重要。
更大的数据集为训练期间提供了多样化的示例以改进泛化性能 
，并支持诸如检索增强生成等有效技术， 以提高推理期间的生成质量。
2. **准确的代码-描述对：**
   每个代码样本都需要是正确、具备功能的，并与其功能的精确描述相关联。
不准确或模糊性可能会在微调或预训练期间误导
LLM， 并在推理期间导致错误的代码生成。
3. **多样化的细节描述层：**
   仅包含高级描述的数据集可能无法为准确的代码生成或有效的
LLM训练提供足够的细节， 由详细描述主导的数据集
可能会限制实际效用。因此 ，一个有效的数据集应以适当的平衡同时包含高级描述和低级的详细描
述。
4. **可扩展性和可集成性：**
   一个高质量的硬件数据集应该允许轻松扩展并集成到各种
项目中。同时硬件设计的快速发展要求数据集能够适应最新的趋势和要求。此外，硬
件设计的开发者可能有特定的关注领域，这使得单一组织难以一次性覆盖所有可能的场景。为了解
决这个问题，数据集的结构应能根据其特定需求进行调整，
使得不同开发者能较为容易地实现协作。这不仅有益于单个
项目，也有助于LLM辅助硬件设计方法的整体进步。

## MG-Verilog数据集
- **数据集概述**：MG-Verilog数据集包含超过11,
000个Verilog代码样本及其对应的自然语言描
述，作为各种LLM辅助硬件设计任务的期望输出和测试输入。
MG-Verilog数据集的构建涉及多个步骤，以确保数据的质量和可用性。

### 数据收集与预处理
从开源仓库收集原始源代码并进行预处理以确保正确
性。借鉴VerilogEval的方法， 使用Pyverilog解析原
始Verilog代码， 排除包含语法错误的代码样本。
应用去重技术以移除冗余的代码样本。此外，提取代码样本的依赖关
系，即识别多模块代码样本的子模块并记录为元数据，
以促进对少样本学习和RAG等技术的研究，用于生成多模块
Verilog代码。
### 描述生成
使用类似于VerilogEval的方法，利用LLM卓越的自然语言生成能力，将自然语言描述附加到代
码样本上。除了简单的高级代码样本。MG-Verilog数据集从原始数据收集到最终数据
集构建都以模块化方式开源，以便于直接扩展。

## 平衡微调方案
引入了一种平衡微调方案，以充分利用MG-Verilog数据集提供的多样化细节水平。
- **存在的挑战：**
微调的最终目标是从高级设计描述中生成硬件代码。
然而， 仅使用简单高级描述进行微调可能无法为LLM提
供足够的信息来生成复杂设计的代码。另一方面，完全
依赖详细描述可能会阻碍LLM响应更高级用户指令的能力。
- **解决方案：** 为了解决上述问题，提出了一
种平衡微调方案，该方案在每次微调迭代中从MG-Ver
ilog数据集中随机选择具有不同描述水平的训练样
本。其目标是在向LLM传授全局和局部代码语义
知识时达到平衡。

## 实验设计
- 1.**数据集生成**：主要基于LLaMA2-70B-Chat模型生成描述，GPT-3.5-turbo只在超出最
大token限制的场景中用作备份， 
temperature 为 0.7 ，top_p 为0.95,其余参数使用默认值
- 2.**微调与推理**：
选择CodeLLaMA-7B-Instruct作为硬件代码生成的
主要模型。
微调方法基于QLoRA，使用其默认训练设置来展示
所提供数据集的有效性。使用来自基准测试中的1
43个Verilog编码问题对微调后的模型进行评
估，这些问题在训练集之外。
- 3.**硬件评估与指标**：
预定义的测试平台案例中检查其RTL仿真结果来测试其有效性。
采用无偏的pass@1、pass@5和pass@10指标，进行20次生
成运行计算得出。
## 实验结果
### 不同评估条件下的消融实验
探索了在训练和评估阶段使用不同数据格式的CodeLLaMA - 7B - Instruct微调模型的性能
。虽然高级的全局摘要最方便用户使用，但其模糊性往往导致所必需的详细信息会缺乏。
表格中，从优到劣表现为：红色(最高)、橙色、浅蓝色、蓝色(最低)。
![MG-Verilog数据集示例](figs/fig-2.png " 三种条件下的性能比较.
")
- **实验结论**：
  1. 用MG - Verilog数据集微调的模型在所有测试的评估设置中都表现出最稳健的性能。
  2. 仅使用过详细或过高级的数据进行训练都会导致性能下降，说明平衡训练数据的重要性。
### 消融与训练样本数的关系
根据实验结果，模型的性能随着训练样本数量的增加而提高。
但是也存在收益递减的现象，从额外的训练样本中获得的性能增益随着样本总数的增加而减少。
![MG-Verilog数据集示例](figs/fig-3.png " 三种条件下训练样本数的增加与通过率.
")
这种行为既可以归因于原始源代码中有限的多样性，也可能是需要更优化的超参数调优和模型配置。
## 创新点
- 构建了统一高级描述与详细描述的首个多粒度硬件数据集与性能标准
- 提出了平衡微调范式，用以平衡LLM在硬件设计中泛化性与解决特定问题的矛盾
- MG-Verilog数据集上微调后的LLM在Verilog代码生成精度方面优于在其他数据集上训练的LLM

## 局限性
- **模型训练数据限制**：由于在预训练期间，硬件数据的暴露不足，它们的性能仍然受到限制
- **数据集限制**：高级描述与详细描述直接存在冲突，需要考虑模型通用性与解决特定问题的能力的冲突
- **硬件应用场景限制**：硬件设计覆盖范围广阔，不同的开发人员可能有特定的关注领域，很难一次性覆盖所有可能的应用场景。

## 未来工作
鼓励其他研究人员参与数据集的扩充，为其增长做出贡献，
使其适应他们的具体需求，从而促进研究社区内部的合作， 
这不仅有利于单个项目， 而且有助于LLM辅助硬件设计方法的整体推进。
## 笔记
[待补充]